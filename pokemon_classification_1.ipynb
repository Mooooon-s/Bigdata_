{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#라이브러리 설치\n",
        "pip install split-folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Import the libraries\n",
        "import zipfile\n",
        "import os\n",
        "zip_ref = zipfile.ZipFile('/content/drive/MyDrive/archive (2)_.zip', 'r') #Opens the zip file in read mode\n",
        "zip_ref.extractall('/tmp/dataset') #Extracts the files into the /tmp folder\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "import tarfile\n",
        "from torchvision.datasets.utils import download_url\n",
        "from torch.utils.data import random_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = '../tmp/dataset/PokemonData'\n",
        "\n",
        "classes = os.listdir(data_dir)\n",
        "print(os.listdir(data_dir))\n",
        "print(len(classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import PIL.ImageOps\n",
        "\n",
        "#다음 변수를 수정하여 새로 만들 이미지 갯수를 정합니다.\n",
        "num_augmented_images = 50\n",
        "\n",
        "file_path = '/tmp/dataset/PokemonData/'\n",
        "dir_names = os.listdir(file_path)\n",
        "total_origin_dir_num = len(dir_names)\n",
        "print(len(dir_names))\n",
        "augment_cnt = 1\n",
        "\n",
        "\n",
        "for i in range(0, total_origin_dir_num):\n",
        "    dir_name = dir_names[i]\n",
        "    file_names=os.listdir(file_path+dir_name)\n",
        "    total_origin_image_num=len(file_names)          #폴더당 이미지 개수\n",
        "    for k in range(0, total_origin_image_num):      #폴더의 이미지만큼 반복\n",
        "      change_picture_index = k\n",
        "      file_name = file_names[change_picture_index]  #전환할 이미지\n",
        "      origin_image_path = '/tmp/dataset/PokemonData/'+dir_name +'/'+file_name\n",
        "      print(origin_image_path)\n",
        "      image = Image.open(origin_image_path)\n",
        "      random_augment = random.randrange(1,3)\n",
        "      save_image_path='/tmp/dataset/PokemonData/'+dir_name+'/'\n",
        "      if(random_augment == 1):\n",
        "          #이미지 좌우 반전\n",
        "          print(\"invert\")\n",
        "          inverted_image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "          inverted_image.save(save_image_path + 'inverted_' + str(augment_cnt) + '.png')   \n",
        "      elif(random_augment == 2):\n",
        "          #이미지 기울이기\n",
        "          print(\"rotate\")\n",
        "          rotated_image = image.rotate(random.randrange(-20, 20))\n",
        "          rotated_image.save(save_image_path + 'rotated_' + str(augment_cnt) + '.png')\n",
        "\n",
        "      augment_cnt += 1  #파일 개수\n",
        "    augment_cnt=1#파일 개수 초기화"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision import transforms\n",
        "import torchvision.datasets as datasets\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import splitfolders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#저장 경로를 drive로 해서 최초 1번만 실행\n",
        "splitfolders.ratio(\"/tmp/dataset/PokemonData\", output=\"/content/drive/MyDrive/preprocessing\",seed=1337, ratio=(.8, .18, .02), group_prefix=None, move=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tf= transforms.Compose([\n",
        "    transforms.Resize((224,224)),transforms.ToTensor(),transforms.Normalize((0.5,),(0.5,))\n",
        "])\n",
        "\n",
        "#미리 드라이브에 저장해놓은 데이터를 로드\n",
        "traindata=datasets.ImageFolder(root='/content/drive/MyDrive/preprocessing/train',transform=tf)\n",
        "testdata=datasets.ImageFolder(root='/content/drive/MyDrive/preprocessing/val',transform=tf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size=32\n",
        "trainloader=DataLoader(traindata,batch_size=batch_size, shuffle=True)\n",
        "testloader=DataLoader(testdata,batch_size=batch_size, shuffle=True)\n",
        "train_images,train_labels=iter(trainloader).next()\n",
        "print(train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D55rQzGJEW5q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torchvision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imbm084UEZqA",
        "outputId": "09757dfe-26ad-4a24-ff80-2dcd64646844"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "train = '/content/drive/MyDrive/ColabNotebooks/PokemonData'\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cH2YSwDXn2-"
      },
      "source": [
        "#ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0pP30RdfSCa"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "resnet50 = models.resnet50(pretrained = True)\n",
        "\n",
        "for param in resnet50.parameters():   #가중치 freeze\n",
        "  param.requires_grad = False\n",
        "\n",
        "num_classes = 150\n",
        "num_ftrs = resnet50.fc.in_features\n",
        "\n",
        "resnet50.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "resnet50.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "optimizer_ft = optim.SGD(resnet50.parameters(), lr=0.001,momentum=0.9)\n",
        "exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size =7, gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7svkqLjuFRxs"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    pbar = tqdm(enumerate(dataloader), total = len(dataloader)) #\n",
        "    learning_loss = 0\n",
        "    sum_loss = 0\n",
        "\n",
        "    for batch, (X, y) in pbar:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        sum_loss = sum_loss + loss.item() #\n",
        "        learning_loss = sum_loss / (batch + 1)\n",
        "        \n",
        "        description = f'train loss : {round(learning_loss, 4)}'\n",
        "        pbar.set_description(description)\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    model.eval()  #\n",
        "    pbar = tqdm(enumerate(dataloader), total = len(dataloader)) #\n",
        "    learning_loss = 0\n",
        "    sum_loss = 0\n",
        "    learning_acc = 0\n",
        "    sum_acc = 0\n",
        "    correct = 0\n",
        "\n",
        "    for batch, (X, y) in pbar:\n",
        "      X, y = X.to(device), y.to(device)\n",
        "\n",
        "      pred = model(X)\n",
        "      loss = loss_fn(pred, y)\n",
        "      correct = (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "      acc = correct / batch_size\n",
        "      sum_acc += acc\n",
        "      learning_acc = sum_acc / (batch + 1)\n",
        "      sum_loss = sum_loss + loss.item() #\n",
        "      learning_loss = sum_loss / (batch + 1)\n",
        "\n",
        "      description = f'test loss : {learning_loss}  || test acc : {learning_acc}'\n",
        "      pbar.set_description(description)\n",
        "\n",
        "    return learning_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nlqX83rsV9_u"
      },
      "outputs": [],
      "source": [
        "epochs = 20\n",
        "best_acc = 0\n",
        "\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "  train(trainloader,resnet50,criterion,optimizer_ft)\n",
        "  acc = test(testloader,resnet50,criterion)\n",
        "  if acc > best_acc:\n",
        "    best_acc = acc\n",
        "    torch.save(resnet50.state_dict(),f'/content/drive/MyDrive/ColabNotebooks/maskmodel_{acc}.pt') #(모델의 현재 파라미터저장,저장경로)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "pokemon_classification",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
